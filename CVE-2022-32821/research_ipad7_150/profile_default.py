from collections import Counter

def analyze_logs_by_file():
    total_occurrence_counter = Counter() # 정렬용: 총 몇 번 나왔는가
    file_presence_counter = Counter()    # 표시용: 몇 개의 파일에 존재하는가
    processed_files_count = 0            # 실제 읽은 파일 개수

    # 1. 파일 5개를 순회
    for i in range(1, 100):
        filename = f'PROFILE_LOG{i}.txt'
        unique_in_this_file = set() # 현재 파일 내 중복 방지용 집합
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    if "kheap_default_ports's default.kalloc.0x4000 kptr = " in line:
                        addr = line.split('=')[1].strip().split()[0]
                        
                        # (1) 전체 카운트 증가 (많이 나온 순서 정렬을 위해)
                        total_occurrence_counter[addr] += 1
                        # (2) 현재 파일 발견 목록에 추가
                        unique_in_this_file.add(addr)
                
                # 파일을 닫기 전, 이 파일에서 발견된 주소들을 파일 카운터에 반영
                for addr in unique_in_this_file:
                    file_presence_counter[addr] += 1
                
                processed_files_count += 1
                
        except FileNotFoundError:
            continue
            # print(f"[!] {filename} 파일이 없습니다.")

    # 2. 결과 출력
    print(f"\n--- 분석 결과 (총 {processed_files_count}개 파일 기준) ---")
    print(f"{'Address':<20} | {'Count':<5} | {'File Freq'}")
    print("-" * 45)

    if processed_files_count == 0:
        print("분석할 파일이 없습니다.")
        return

    # 3. 상위 10000개 출력 (기준: 총 등장 횟수)
    # File Freq는 '발견된 파일 수 / 전체 파일 수' 로 표현
    for addr, count in total_occurrence_counter.most_common(10000):
        in_files = file_presence_counter[addr]
        print(f"{addr:<20} | {count:<5} | {in_files}/{processed_files_count}")

if __name__ == "__main__":
    analyze_logs_by_file()